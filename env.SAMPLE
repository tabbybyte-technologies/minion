# Minion CLI Configuration
# Copy this file to .env and fill in your API keys
MINION_DEBUG=no

# Choose your AI provider: openai, anthropic, google, or local
MINION_PROVIDER=openai

# Optional: Control LLM output randomness (0.0 = deterministic, 1.0 = creative)
MINION_TEMPERATURE=0.3

# OpenAI Configuration
MINION_OPENAI_API_KEY=your_openai_api_key_here
MINION_OPENAI_MODEL=gpt-4

# Anthropic Configuration (if using MINION_PROVIDER=anthropic)
# MINION_ANTHROPIC_API_KEY=your_anthropic_api_key_here
# MINION_ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Google Configuration (if using MINION_PROVIDER=google)
MINION_GOOGLE_API_KEY=your_google_api_key_here
MINION_GOOGLE_MODEL=gemini-2.0-flash-lite

# Local LLM Configuration (if using MINION_PROVIDER=local)
# MINION_LOCAL_API_URL=http://localhost:1234/v1
# MINION_LOCAL_API_KEY=local
# MINION_LOCAL_MODEL=llama2
